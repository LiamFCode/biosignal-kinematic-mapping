# Biosignal Kinematics Mapping

## Introduction
First things first, the concept. The idea of this project is to gather as much information on the utilization of biosignals picked up by electrodes using EMGs as seen in prosthesis, and EEG-based BCI techniques to create a 3d model of a forearm and hand that mimics the exact real hand motions in real time, or under 250ms (human visual reaction time). This model can be used for a number of different things, such as virtual or augmented reality, video games, remote control of things such as drones or wheeled vehicles, control of robotic arms, or interpreted gestures from sign language into text, which can be outputed with text to speech for deaf or non-verbal users. The latter 2 can even be used combined to train a pair of robotic hands to translate speech to sign language for presentations or the like.

**EMG**: electromyogram; **EEG**: electroencephalogram; **BCI**: brain - computer interface; **Biosignals**: electrical, mechanical, or chemical signals generated by a living organism
