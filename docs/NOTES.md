# Biosignal Kinematics Mapping


## Introduction
   The idea of this project is to research and design a tool with utilization of biosignals picked up by electrodes using EMGs as seen in prosthesis, and EEG-based BCI techniques to create a 3d model of a forearm and hand that mimics the exact motions of the real hand in real time, or under 250ms (human visual reaction time). This model can be used for a number of different things, such as virtual or augmented reality, video games, remote control of things such as drones or wheeled vehicles, control of robotic arms, or interpreted gestures from sign language into text, which can be outputed with text to speech for deaf or non-verbal users. The latter 2 can even be used together to train a pair of robotic hands to translate speech into sign language for presentations.

**EMG**: electromyogram; **EEG**: electroencephalogram; **BCI**: brain - computer interface; **Biosignals**: electrical, mechanical, or chemical signals generated by a living organism
